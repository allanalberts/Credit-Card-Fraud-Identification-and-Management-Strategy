{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cost Sensitive Analysis Structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can predetermine each transactions operational cost based on our models fraud prediction for the transaction:\n",
    "* Legitimate Transactions (false negative, FN) - no cost, transactions passes through the model\n",
    "* Misclassified as Fraud (false positive, FP) - ReviewCost\n",
    "* Undetected fraud (false positive, FP) - amount of transaction (successful fraud attempt) & chargeback fee\n",
    "* Detected fraud (true positive, TP) - ReviewCost\n",
    "\n",
    "These potential costs can be written to a cost matrix that has the same number of rows as our dataset. The cost matrix is then applied to the predicted results using the following logic. The associated Boolean Truth tables demonstate how the logic isolates the transactions for each of the four possible matrix outcomes (FN, FP, FP, TP):\n",
    "\n",
    "<img src=\"../images/cost_matrix_formulas.jpg\" alt=\"Drawing\" style=\"width: 600px;\"/>\n",
    "\n",
    "The function cs_confusion_matrix uses these formulas to construct a cost-sensitive confusion matrix which oulines the total operation costs, including misclassification costs, associated with our fraud prediction model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cs_confusion_matrix(y_test, y_pred, cost_matrix):\n",
    "    '''\n",
    "    Returns a cost sensitive confusion matrix using the cost matrix\n",
    "    '''\n",
    "    cost_TN = np.sum((1 - y_test) * (1 - y_pred) * cost_matrix[:, 0])\n",
    "    cost_FP = np.sum((1 - y_test) * y_pred * cost_matrix[:, 1])\n",
    "    cost_FN = np.sum(y_test * (1 - y_pred) * cost_matrix[:, 2])\n",
    "    cost_TP = np.sum(y_test * y_pred * cost_matrix[:, 3])\n",
    "    return np.array([[cost_TN, cost_FP],[cost_FN, cost_TP]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Cost Matrix based on the Fraud Management Operational Strategy\n",
    "Once we identify the transactions suspected to be fraudulent, they will be placed in a Fraud Review Queue to be manually inspected by fraud analysts to determine their legitimacy and those that are found to be fraud will be cancelled. There are multiple approaches to how this fraud review process can be managed. One approach would be to review all suspected fraud transactions while another approach would be to automatically cancel some of the suspected fraud without manaully reviewing the transactins. These different operatinal strategies have different impacts on our fraud losses, operational expenses and customer satisfaction. By building different cost matrix, we can measure what the impacts would be from employing different operational strategies. \n",
    "\n",
    "We will start by optimizing a model based on a manual review of all suspected fraud transactions and then, once this model is build, we will test the impact of an auto-decline strategy where we automatically decline suspected fraud transactions with dollar amounts that exceed our average cost of reviewing a transaction.\n",
    "\n",
    "**Full Review model costs**:\n",
    "- False negative - Undetected fraud transactions = Transaction Amount plus a ChargebackFee assessed by our credit card processor\n",
    "- True positive - Correctly classified fraud transactions = ReviewCost\n",
    "- False positive - Misclassified Legitimate transactions = ReviewCost\n",
    "\n",
    "<img src=\"../images/cost_matrix1.jpg\" alt=\"Drawing\" style=\"width: 350px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FullReview(c):\n",
    "    '''\n",
    "    Returns a cost_matrix that contains, for every transaction, the four possible costs associated with it depending\n",
    "    on the outcome of its classification (TN, FP, FN, TP). The function must be an array c which contains\n",
    "    the amount of each transaction. The model assumes we will manually review all suspected fraud transactions\n",
    "    and cancel those in which fraud is confirmed.     \n",
    "    ''' \n",
    "    n_samples = c.shape[0]\n",
    "    cost_matrix = np.zeros((n_samples, 4))\n",
    "    # True Negative: correctly predicted as legitimat\n",
    "    cost_matrix[:, 0] = 0.0\n",
    "    \n",
    "    # False Positive: incorrectly predicted as fraud.\n",
    "    cost_matrix[:, 1] = ReviewCost                                                               \n",
    "    \n",
    "    # False Negative: undetected fraud.\n",
    "    cost_matrix[:, 2] = c + ChargebackFee \n",
    "\n",
    "    # False Negative: correctly prediced as fraud.\n",
    "    cost_matrix[:, 3] = ReviewCost\n",
    "\n",
    "    return cost_matrix "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Partial Review Model**:\n",
    "Suspected fraud transactions are only reviewed if their amount exceeds our ReviewCost. It this model we have a risk of cancelling some legitimate transactions. When this occurs we will loose the profit from these transactions which we will assume is 50 percent of their total amount. Therefore the costs associated with an auto-cancel model are:\n",
    "\n",
    "- False negative - Undetected fraud transactions = Transaction Amount plus a ChargebackFee assessed by our credit card processor\n",
    "- True positive - Correctly classified fraud transactions = ReviewCost when transaction amount > ReviewCost\n",
    "- False positive - Misclassified Legitimate transactions = ReviewCost when transaction amount > ReviewCost, otherwise it is the profit from this lost sale which is 50 percent of the transaction amount.\n",
    "<img src=\"../images/cost_matrix2.jpg\" alt=\"Drawing\" style=\"width: 350px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PartialReview(c):\n",
    "    '''\n",
    "    Returns a cost_matrix that contains, for every transaction, the four possible costs associated with it depending\n",
    "    on the outcome of its classification (TN, FP, FN, TP). The function must be an array c which contains\n",
    "    the amount of each transaction. The model assumes we will only manually review suspected fraud transactions\n",
    "    with a value less than the ReviewCost. \n",
    "    ''' \n",
    "    n_samples = c.shape[0]\n",
    "    cost_matrix = np.zeros((n_samples, 4))\n",
    "    \n",
    "    # True Negative: correctly predicted as legitimate\n",
    "    cost_matrix[:, 0] = 0.0 \n",
    "    \n",
    "    # False Positive: incorrectly predicted as fraud. Reviewed only if transaction amount exceeds the review cost.\n",
    "    # Cost: ReviewCost if reviewed, otherwise half of the transaction amount (estimated profit lost from cancellng trans)\n",
    "    cost_matrix[:, 1] = np.where(c>=ReviewCost, ReviewCost, c*0.5)                                                               \n",
    "    \n",
    "    # False Negative: undetected fraud. Cost: Amount of transaction plus a chargeback fee\n",
    "    cost_matrix[:, 2] = c + ChargebackFee \n",
    "    \n",
    "    # False Negative: correctly prediced as fraud. Reviewed only if transaction amount exceeds the review cost.\n",
    "    # Cost: ReviewCost if transaction is reviewed.\n",
    "    cost_matrix[:, 3] = np.where(c>=ReviewCost, ReviewCost, 0)\n",
    "\n",
    "    return cost_matrix "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Auto-Cancel model**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NoReview(c):\n",
    "    '''\n",
    "    Returns a cost_matrix that contains, for every transaction, the four possible costs associated with it depending\n",
    "    on the outcome of its classification (TN, FP, FN, TP). The function must be an array c which contains\n",
    "    the amount of each transaction. The model assumes all transaction suspected of fraud will be cancelled without\n",
    "    a manual review.\n",
    "    ''' \n",
    "    n_samples = c.shape[0]\n",
    "    cost_matrix = np.zeros((n_samples, 4))\n",
    "    \n",
    "    # True Negative: correctly predicted as legitimate\n",
    "    cost_matrix[:, 0] = 0.0 \n",
    "    \n",
    "    # False Positive: incorrectly predicted as fraud. Cost: half of the transaction amount (estimated profit lost\n",
    "    # from cancellng trans)\n",
    "    cost_matrix[:, 1] = c*0.5                                                             \n",
    "    \n",
    "    # False Negative: undetected fraud. Cost: Amount of transaction plus a chargeback fee\n",
    "    cost_matrix[:, 2] = c + ChargebackFee \n",
    "    \n",
    "    # False Negative: correctly prediced as fraud. \n",
    "    cost_matrix[:, 3] = 0.0\n",
    "\n",
    "    return cost_matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Class_Probabilities(clf, X_train, y_train, X_test, y_test, cost_matrix=None):\n",
    "    '''\n",
    "    Fits the pipeline stored in classifiers dictionary under subkey ['pipeline'] on X_train, y_train data.\n",
    "    Calculates probabilities for each sample in data X_test. Uses the predictions to create both regular and \n",
    "    cost-sensitive confusion matrices which are then stored in the classifiers dictionary structure.\n",
    "    '''\n",
    "    pipeline = classifiers[clf]['pipeline'].fit(X_train, y_train)\n",
    "    classifiers[clf][\"pred_prob\"] = pipeline.predict_proba(X_test)[:,1]\n",
    "            \n",
    "    # store confusion matrix values - use pred_prob since generated through cross validation        \n",
    "    classifiers[clf][\"cnf_matrix\"] = confusion_matrix(y_test,classifiers[clf][\"pred_prob\"]>=classifiers[k][\"threshold\"])\n",
    "    if cost_matrix is not None:\n",
    "        classifiers[clf][\"cs_cnf_matrix\"] = cs_confusion_matrix(y_test, classifiers[clf][\"pred_prob\"]>=classifiers[k][\"threshold\"],\n",
    "                                                              cost_matrix)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CV_Class_Probabilities(clf, X, y, cost_matrix=None, TimeIt=False):\n",
    "    '''\n",
    "    Runs cross validation on the pipeline stored in the classifiers dictionary under subkey ['pipeline']\n",
    "    using X and y data. Calculates probabilities for each sample in data X_test. Uses the predictions to \n",
    "    create both regular and cost-sensitive confusion matrices which are then stored in the classifiers \n",
    "    dictionary structure. Displays cross validation execution time if TimeIt=True.\n",
    "    '''\n",
    "    start_time = time.time()\n",
    "\n",
    "    classifiers[clf][\"pred_prob\"] = cross_val_predict(classifiers[clf][\"pipeline\"], X, y,\n",
    "                                                      cv=StratifiedKFold(n_splits=FOLDS, \n",
    "                                                      shuffle=True, random_state=SEED), \n",
    "                                                      method=\"predict_proba\")[:,1]\n",
    "    if TimeIt:\n",
    "        print(\"{:.0f} seconds cross_val_predict execution time for {} classifier\".format((time.time() - start_time), k))\n",
    "            \n",
    "    # store confusion matrix values - use pred_prob since generated through cross validation        \n",
    "    classifiers[clf][\"cnf_matrix\"] = confusion_matrix(y,classifiers[clf][\"pred_prob\"]>=classifiers[clf][\"threshold\"])\n",
    "    if cost_matrix is not None:\n",
    "        classifiers[clf][\"cs_cnf_matrix\"] = cs_confusion_matrix(y, classifiers[clf][\"pred_prob\"]>=classifiers[clf][\"threshold\"],\n",
    "                                                              cost_matrix)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "def Plot_Confusion_Matrix(cm, title, classes=['Legitimate','Fraud'],\n",
    "                          cmap=plt.cm.Blues, currency=False):\n",
    "    \"\"\"\n",
    "    Plots a single confusion matrix. If currency=True then displays results as currency.\n",
    "    \"\"\"   \n",
    "    if currency:\n",
    "        plt.title(f'{title}\\nCost Matrix')\n",
    "    else:\n",
    "        plt.title(f'{title}\\nConfusion Matrix')\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=0)\n",
    "    plt.yticks(tick_marks, classes, rotation=90)\n",
    "    \n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        cost=cm[i, j]\n",
    "        if currency:\n",
    "            cost = f'${cost:0,.2f}' \n",
    "        plt.text(j, i, cost, horizontalalignment=\"center\", \n",
    "        color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Plot_Multiple_Confusion_Matrix(clf_list, CostSensitive):\n",
    "    '''\n",
    "    Plots multiple side by side confustion matrices of the classifiers in clf_list.\n",
    "    If cost_matrix included, then confusion matrix will represent costs instead of occurrances.\n",
    "    '''\n",
    "    fig = plt.figure(figsize=(16, 4))\n",
    "    p=1 \n",
    "    for k in clf_list:\n",
    "        fig.add_subplot(1, len(clf_list), p)\n",
    "        if CostSensitive:\n",
    "            Plot_Confusion_Matrix(classifiers[k][\"cs_cnf_matrix\"], k, cmap=classifiers[k][\"cmap\"], currency=True)\n",
    "        else:\n",
    "            Plot_Confusion_Matrix(classifiers[k][\"cnf_matrix\"], k, cmap=classifiers[k][\"cmap\"], currency=False)\n",
    "        p+=1\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate classifier prediction probabilities and plot cost matrix \n",
    "for k in clf_list:\n",
    "    Class_Probabilities(k, X_train, y_train, X_test, y_test, cost_matrix=FullReview(c_test))  \n",
    "\n",
    "# plot the confusion matrix for all models in the list clf_list:    \n",
    "Plot_Multiple_Confusion_Matrix(clf_list, CostSensitive=False)\n",
    "Plot_Multiple_Confusion_Matrix(clf_list, CostSensitive=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Business_Metrics(k, y, c):\n",
    "    classifiers[k][\"TotalCosts\"] = classifiers[k][\"cs_cnf_matrix\"].sum()\n",
    "    classifiers[k][\"SavingsPercent\"] = (TotalFraud(c,y) - classifiers[k][\"TotalCosts\"]) / TotalFraud(c,y)\n",
    "    classifiers[k][\"ReviewQueueSize\"] = classifiers[k]['cnf_matrix'][0,1] + classifiers[k]['cnf_matrix'][1,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Plot_TotalCost(models, c, y, axes=None):\n",
    "    '''\n",
    "    Plots the cost metric (total operational cost of fraud management model) for \n",
    "    classifiers in clf_list. Plots the operational budeget target as a dashed line on plot.\n",
    "    '''\n",
    "    colors = []\n",
    "    clf_desc = []\n",
    "    for k in models:\n",
    "        colors.append(classifiers[k][\"c\"])\n",
    "        clf_desc.append(classifiers[k][\"clf_desc\"])\n",
    "    results = pd.DataFrame.from_dict(classifiers, orient='index')[[\"clf_desc\",\"TotalCosts\"]].ix[clf_list]\n",
    "    results = results.reindex(clf_list)\n",
    "    results.set_index('clf_desc', inplace=True)\n",
    "    if axes==None:\n",
    "        results.T.plot(kind='bar', color=colors, alpha=0.5, rot=0, legend=False) \n",
    "        plt.axhline(y=TotalLegit(c,y)*FraudBudget, color='black', linestyle='dashed')\n",
    "    else:    \n",
    "        results.T.plot(kind='bar', color=colors, alpha=0.5, rot=0, legend=False, ax=axes) \n",
    "        axes.axhline(y=TotalLegit(c,y)*FraudBudget, color='black', linestyle='dashed')\n",
    "    axes.set_title(\"Costs vs. Budget (dashed line)\")\n",
    "    axes.legend(loc='lower right') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Metrics_Dashboard(models, y, c): \n",
    "    for k in models:\n",
    "        Business_Metrics(k, y, c)\n",
    "        print('{} SavingsPercent: {:.2f}%  Recall: {} Basis Points: {:.1f}'.format(k,classifiers[k]['SavingsPercent']*100,\n",
    "                                                        classifiers[k]['Recall_score'],                \n",
    "                                                        10000*classifiers[k][\"TotalCosts\"]/TotalLegit(c,y)))\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(18, 4))\n",
    "    Plot_TotalCost(models, c, y, axes[0])\n",
    "    Plot_SavingsPercent(models, axes[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
